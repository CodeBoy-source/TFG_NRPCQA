\chapter{Fundamentos Teóricos}
Esta sección tiene el objetivo de introducir y explicar brevemente los
fundamentos teóricos en los que se basan los métodos empleados en este
proyecto, así como justificar su relevancia en la resolución del problema que
se plantea.

\subsection{Subproblemas de la IQA}
\changed[{En respuesta a Enrique, se cambia esta sección a Fundamentos}]{Sección Intro. subproblemas a Fundamentos. IQA}
Existen tres subproblemas presenten en el ámbito de \emph{IQA}. Los primeros, son problemas 
dónde tenemos acceso a la imagen original, que suponemos exenta de desperfectos, 
en la cual se pueden aplicar métodos basados en diferencia de características 
entre ambas, como puede ser al nivel del color de píxel posición a posición,
y se denomina ``\emph{Full Reference}''(\emph{FR}). 
La tarea, aparentemente sencilla, en realidad presenta una complejidad alta dada por 
la necesidad de codificar la percepción humana a la hora de calificar la calidad 
de una imagen\cite{WhyIsIQASoDifficult}. Ya que métricas que miden distancias no suelen 
ser suficientes al no haber buena correlación entre la calidad percebida y el 
resultado de la métrica.


\corrected[{Hablar de las limitaciones de métricas de distancias}]{
La mayoría de las veces no se menciona, pero al optar métodos de sensibilidad 
al error (distancias) se imponen un conjunto de suposiciones cuestionables. 
Primeramente se asume la misma importancia para todas las señales de la imagen, que
la magnitud del error es lo único que determina la calidad, que el contenido de la imagen 
no afecta al resultado final tras aplicar una distorsión y que si cambiamos el 
orden de las señales la medida de distorsión no es afectada.
Lamentablemente, ninguna de estas suposiciones se cumplen\cite{Wang2006ModernIQ}, ver imágenes~(\ref{fig:FailureMinkowskiMetric},\ref{fig:MSEHyperSphere}).
}
 
El siguiente subproblema es aquel donde tenemos algún tipo de información adicional respecto 
a la imagen original en el momento de análisis de la calidad de la imagen final,
denominados ``\emph{Reduced Reference}''(\emph{RR}). La información extra puede incluir características estadísticas, metadatos, parámetros 
de compresión o características extraídas de una región de interés específica.
 
Y por último, tenemos aquellos problemas donde desconocemos el origen y cualquier 
información respecto a la imagen inicial, denominados problemas ``\emph{No reference}''(\emph{NR}).
Estas métricas están exentas de cualquier información de referencia y se 
centran en capturar características generales de calidad. 

\corrected[{Enfatizar las diferencias en dificultad}]{
La evaluación de calidad de imagen sin referencia es, quizás, el problema 
más difícil en el análisis de imágenes. De cierto modo, el modelo debe ser 
capaz de evaluar la calidad cualquier imagen sin saber nada de la imagen ``real'' original. 
Superficialmente parece ``misión imposible''. No obstante, sorprendemente esa 
es una tarea muy sencilla para el ser humano\cite{Wang2006ModernIQ}. 


Para resolverlo, debemos disponer de conocimientos de la naturaleza de las imágenes 
de las que tratamos y los efectos de las distorsiones. Lo que se denomina 
estadísticas naturales de escena (NSS, por sus siglas en inglés). Un ejemplo 
sería JPEG, un algoritmo de compresión que se codifica por bloques 8x8. Los efectos
negativos de la compresión se representan por el difuminado entre bloques y los artefactos que presentan.
Entender estos efectos permite diseñar métricas específicas\cite{SpatialDomainForJPEG, FrecuencyDomainForJPEG}


As veces resulta difícil describir las características de la imagen y los efectos 
de la distorsión. Es por ello que los métodos de aprendizaje profundo son cada vez 
más frecuente y dan mejores resultados. Permitimos que sea la máquina la que aprenda 
las propiedades de la distorsión, su relación con el contenido y efecto sobre la 
percepción visual\cite{Hallucinated-IQA, BIQA, DIPIQA}. 
}

La complejidad del problema crece conforme nos desplazamos a las tres dimensiones. 
El analizar la calidad de los modelos \emph{3D} implica mayor nivel de dificultad 
dado que nos enfrentamos a dos grandes retos: La complejidad computacional 
de las operaciones y la escasez de bases de datos etiquetadas
sobre objetos tridimensionales para entrenar y evaluar modelos. 
 
Para las nubes de puntos, que representan una colección de puntos en un espacio 
tridimensional $(x,y,z)$ cada uno con un color asociado \emph{RGB}, se pueden emplear métricas y algoritmos basándose en criterios como la 
densidad de puntos, la uniformidad, la precisión geométrica y la detección de artefactos.
También se pueden considerar aspectos relacionados con la coherencia de los colores 
o texturas asociadas a los puntos\cite{NR3DQA, StructureGuidedResampling, GPA-NET} 
 
Un enfoque común es la evaluación de calidad de una nube de puntos tridimensional 
mediante proyecciones \emph{2D} desde diferentes perspectivas\cite{IT-PCQA, VQA-PC, MM-PCQA}. 
De esta forma podemos tratar el problema como uno de \emph{IQA} 2D reduciendo la 
complejidad computacional, pudiendo implementar métodos y soluciones ya existentes.

Teniendo en cuenta todas estas consideraciones, el presente TFG aborda la
estimación, sin referencia, de calidad de imágenes médicas en espacio tridimensional.

\begin{figure}[htp]
  \begin{center}
    \includegraphics[width=0.5\textwidth]{imagenes/chapter2/failure_minkowski_metric.png}
  \end{center}
  \caption{En este ejemplo, extraído de\cite{MinkowskiFailure},
  vemos que sumar una constante positiva a una imagen  de referencia (a) produce la imagen (b) que contiene la misma distancia \emph{Minkowski}\footnotemark[1]
  que (c), imagen fabricada por la misma constante pero permutando signo de forma aleatoria. Siendo que
  la percepción final es que la imagen (c) es peor que la (b).
\label{fig:FailureMinkowskiMetric}}
\end{figure}
\begin{figure}[htp]
  \begin{center}
    \includegraphics[width=0.5\textwidth]{imagenes/chapter2/MSE_Hypersphere.png}
  \end{center}
  \caption{En este ejemplo, extraído de\cite{Wang2006ModernIQ}, la misma imagen distorsionada de distintas maneras
  resulta en el mismo valor \emph{MSE}\footnotemark[2]=181. Siendo evidente que 
  algunas distorsiones producen efectos visuales más marcados que otras haciendo 
  que no sea una buena estimación perceptual de la calidad.}
  \label{fig:MSEHyperSphere}
\end{figure}

\footnotetext[1]{La distancia de \emph{Minkowski} es una métrica 
vectorial que puede considerarse como una generalización tanto de 
la distancia euclidia como de la distancia de Manhattan . }
\footnotetext[2]{\emph{MSE}: \emph{Mean squared error} o error cuadrático medio 
  es una métrica de distancia que se calcula como la media de la suma de las 
  diferencias al cuadrado.}

\section{Aprendizaje Automático}
El aprendizaje automático\cite{IAModernApproach} o \emph{MachineLearning} (\emph{ML}) 
es una de las ramas que compone lo que definimos como 
la inteligencia artificial (\emph{IA}). Esta última se puede definir, 
según\cite{WhatIsAI}, como 
``La ciencia e ingeniería 
de crear máquinas inteligentes, especialmente programas de computadora inteligentes. 
Está relacionada con la tarea similar de utilizar computadoras para comprender 
la inteligencia humana...''

En este caso hablamos de dar soluciones a problemas complejos sin 
solución analítica (o que resulta muy costoso hallarla), es decir, necesitamos que la computadora sea la que identifique
los patrones en los datos y realice predicciones sobre ellos\cite{LearningFromData}.
Se puede definir más formalmente que un programa aprende de la experiencia E con
respecto a alguna clase de tareas T y una métrica de rendimiento P si su
rendimiento en las tareas T, medido con P, mejora con la experiencia E\cite{TomMitchell}.

Dependiendo de factores como las necesidades del problema, la naturaleza
de los datos a utilizar o el objetivo a alcanzar, podemos encontrar distintos tipos de
algoritmos de aprendizaje. En este documento se recogerán dos grandes grupos: aprendizaje supervisado 
y aprendizaje no supervisado. En el primero disponemos de un conjunto de datos 
anotados, es decir, con las salidas deseadas para cada ejemplo y en el segundo 
se espera que sea la máquina la que determine los patrones~(\ref{fig:MLExamples}). 

En general se suelen aplicar las técnicas de \emph{ML} sobre grandes conjuntos 
de datos sobre los cuales deseamos detectar los patrones subyacientes\cite{
DataMiningHandbook}.

Puede observarse que dada estas descripciones, al problema presente podemos 
aplicarle alguna técnica de \emph{ML}: Tenemos datos de entrada (nubes de puntos 
distorsionadas) y una salida (valor de calidad). Además, existen conjuntos de 
datos públicos etiquetadas para distintos tipos de distorsiones. Esto significa que
estamos entre un problema de aprendizaje supervisado.

\begin{figure}[htp]
  \centering
    \begin{subfigure}{.45\textwidth}
  \centering
  \includegraphics[width=0.8\linewidth]{imagenes/chapter2/BeforeSVMExample.png} 
  \tikz[remember picture]\node[inner sep=0pt,outer sep=0pt] (a) {}; 
    \end{subfigure}
    \begin{subfigure}{.45\textwidth} 
  \centering
  \tikz[remember picture]\node[inner sep=0pt,outer sep=0pt] (b) {}; \includegraphics[width=0.8\linewidth]{imagenes/chapter2/AfterSVMExample.png}
    \end{subfigure}
  \tikz[remember picture,overlay]\draw[line width=1pt,-stealth,black] ([xshift=2mm,yshift=2.8cm]a.east) -- ([xshift=-2mm, yshift=2.8cm]b.west)node[midway,above,text=black,font=\LARGE\bfseries\sffamily] {};

    \begin{subfigure}{.45\textwidth}
  \centering
  \includegraphics[width=0.8\linewidth]{imagenes/chapter2/BeforeClusteringExample.png} 
  \tikz[remember picture]\node[inner sep=0pt,outer sep=0pt] (c) {}; 
    \end{subfigure}
    \begin{subfigure}{.45\textwidth} 
  \centering
  \tikz[remember picture]\node[inner sep=0pt,outer sep=0pt] (d) {}; \includegraphics[width=0.8\linewidth]{imagenes/chapter2/AfterClusteringExample.png}
    \end{subfigure}
  \tikz[remember picture,overlay]\draw[line width=1pt,-stealth,black] ([xshift=2mm,yshift=2.8cm]c.east) -- ([xshift=-2mm, yshift=2.8cm]d.west)node[midway,above,text=black,font=\LARGE\bfseries\sffamily] {};

  \caption{Ejemplo de aprendizaje supervisado y no supervisado. En el primer par, 
  vemos como dado un conjunto de clases etiquetadas aprendemos un hiper plano que 
  las separa. En el segundo, dado un conjunto de puntos aprendemos un conjunto de clases.
}
  \label{fig:MLExamples}
\end{figure}


\section{Aprendizaje Profundo}
El aprendizaje profundo o \emph{Deep Learning} (\emph{DL}) 
\subsection{Redes Convolucionales} 
\subsection{Aplicadas a Videos} 
\section{Ensemble o Conjunto \emph{Deep Learning}}
\section{Imágenes médicas, Métricas y Distorsiones}
\label{sec:Distorsiones}
